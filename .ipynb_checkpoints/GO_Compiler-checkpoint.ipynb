{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Universidade Federal de Campina Grande - UFCG](http://www.ufcg.edu.br/)\n",
    "### [Departamento de Sistemas e Computação](http://www.computacao.ufcg.edu.br/)\n",
    "#### Disciplina: [Compiladores](http://www.dsc.ufcg.edu.br/~franklin/disciplinas/2018-1/Compiladores/)\n",
    "#### Professor: [Franklin Ramalho](http://www.dsc.ufcg.edu.br/~franklin/pp/)\n",
    "\n",
    "##### Alunos:\n",
    "- [Paulo Sérgio]( mailto:paulo.araujo@ccc.ufcg.edu.br )\n",
    "- [Lucas Diniz]( mailto:d@ccc.ufcg.edu.br )\n",
    "- [Felipe ?]( mailto:f@ccc.ufcg.edu.br )\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fases da construção de um compilador \n",
    "Para construirmos um compilador que traduza código GO para Assembly temos que atender as etapas clássicas na construção de um compilador, sendo estas: \n",
    "    1. Análise Léxica \n",
    "    2. Análise Sintática\n",
    "    3. Análise Semântica \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Análise Léxica \n",
    "Para fazer a análise léxica usaremos a ferramenta [JFLEX](http://jflex.de), que é uma analisador léxico excrito em java. \n",
    "\n",
    "TO-DO // REFACTOR TUDO daqui pra baixo. \n",
    "\n",
    "##### Como ligar CUP com o projeto. \n",
    "```java\n",
    "import java_cup.runtime.*;\n",
    "import cup.sym; //<< código customizado?\n",
    "\n",
    "%% \n",
    "%cup\n",
    "%cupdebug\n",
    "\n",
    "%{\n",
    "       \n",
    "       private Symbol symbol(int type) {\n",
    "           return new Symbol(type, yyline, yycolumn);\n",
    "          }\n",
    "       \n",
    "        private Symbol symbol(int type, Object val) {\n",
    "           return new Symbol(type, yyline, yycolumn, val);\n",
    "          }\n",
    "          \n",
    "%}\n",
    "%% \n",
    "   ...\n",
    "   {Numero}+{IS}?                            { return symbol(sym.CONSTANT, new String(yytext())); }\n",
    "\n",
    "```\n",
    "\n",
    "Isso deveria gerar uma saída que vai será o parser da linguagem depois. \n",
    "\n",
    "Links:\n",
    "\n",
    "    https://johnidm.gitbooks.io/compiladores-para-humanos/content/part1/lexical-analysis.html\n",
    "\n",
    "    https://johnidm.gitbooks.io/compiladores-para-humanos/content/part2/building-the-first-lexical-analyzer-with-JFlex.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Executando a Análise Léxica \n",
    "\n",
    "Abaixo é utilizada a função popen de python que executa um comando e retorna um objeto com informações sobre a execução do comando. \n",
    "\n",
    "O código é claro: \n",
    "    1. As regras léxicas são passadas para o JFLEX\n",
    "    2. Ele cria um DFA (Lexer.java) que nos ajudará a processar os tokens da linguagem.\n",
    "    3. O código fonte é passado para o reconhecedor léxico(Lexer) que imprime os valores casados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###### Criação de Lexer.java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading \"src\\flex\\rules.flex\"\n",
      "\n",
      "Warning : Macro \"comment\" has been declared but never used.\n",
      "Constructing NFA : 530 states in NFA\n",
      "Converting NFA to DFA : \n",
      "........................................................................................................................................................................................................................\n",
      "218 states before minimization, 114 states in minimized DFA\n",
      "Old file \"src\\flex\\Lexer.java\" saved as \"src\\flex\\Lexer.java~\"\n",
      "Writing code to \"src\\flex\\Lexer.java\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from os import popen\n",
    "print(popen('java -jar lib/jflex-1.6.1.jar src/flex/rules.flex').read()) # Cria um Lexer das regras da análise léxica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###### Alimentação do Lexer Padrão com código fonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found inline comment: simplest possible program\n",
      "\n",
      "Found keyword: package\n",
      "Found identifier: main\n",
      "Found keyword: func\n",
      "Found identifier: main\n",
      "Found operator/punctuation: (\n",
      "Found operator/punctuation: )\n",
      "Found operator/punctuation: {\n",
      "Found identifier: println\n",
      "Found operator/punctuation: (\n",
      "Found string literal: \"Hello World!\"\n",
      "Found operator/punctuation: )\n",
      "Found operator/punctuation: }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(popen('javac src/flex/Lexer.java').read()) # Compila o Lexer \n",
    "print(popen('java -cp ./src flex.Lexer test/input/001.go').read()) # utiliza o Lexer compilado para análisar os tokens encontrados no programa fonte"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
